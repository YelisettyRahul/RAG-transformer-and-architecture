{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b569b846-8a2c-433c-b2c6-9af4731cb58a",
   "metadata": {},
   "source": [
    "Basic text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fcdfca-0588-4515-b653-6e13d6516a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (4.50.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0f8f0d-c9d5-4c10-9601-32d63ef47dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yelisetty rahul\\music\\aiml\\env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c699b4bf-c47c-4d93-8481-5110e93ff313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fa46af-87f7-40ad-9b98-3963294ffe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d3f7f8-6cb9-4712-b28d-e5c25c9bb834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Dear boss ... \\xa0I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding the prompt to get the input ids\n",
    "prompt = \"Dear boss ... \"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\") # pt = pytorch\n",
    "\n",
    "# Generate text using the model\n",
    "outputs = model.generate(input_ids, max_length = 100)\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True) # decode output to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d8dcb3-3c7b-4082-8565-b15b84e95f1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Simplified text generation function\n",
    "def simple_text_generation(prompt, model, tokenizer, max_length = 100):\n",
    "  # Encoding the prompt to get the input ids\n",
    "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\") # pt = pytorch\n",
    "\n",
    "  # Generate text using the model\n",
    "  outputs = model.generate(input_ids, max_length = 100)\n",
    "\n",
    "  # Decode the generated output IDs back into text\n",
    "  return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383b7f8-e187-422b-84a8-4525c1f46185",
   "metadata": {},
   "source": [
    "Notice the repetitive nature of the output => we need to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5573c007-85ab-405a-8d87-9c763044a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear boss ... Â I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able to do this. I'm not going to be able\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "prompt = \"Dear boss ... \"\n",
    "text_generated = simple_text_generation(prompt,\n",
    "                                        model,\n",
    "                                        tokenizer,\n",
    "                                        max_length = 100)\n",
    "print(text_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd551b-fea9-4145-9fa0-5653142bedec",
   "metadata": {},
   "source": [
    "Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8990b3c-9c6d-45c2-b44a-8cb7d925cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (scientific research abstracts related to machine learning)\n",
    "data = [\n",
    "    \"This paper presents a new method for improving the performance of machine learning models by using data augmentation techniques.\",\n",
    "    \"We propose a novel approach to natural language processing that leverages the power of transformers and attention mechanisms.\",\n",
    "    \"In this study, we investigate the impact of deep learning algorithms on the accuracy of image recognition tasks.\",\n",
    "    \"Our research demonstrates the effectiveness of transfer learning in enhancing the capabilities of neural networks.\",\n",
    "    \"This work explores the use of reinforcement learning for optimizing decision-making processes in complex environments.\",\n",
    "    \"We introduce a framework for unsupervised learning that significantly reduces the need for labeled data.\",\n",
    "    \"The results of our experiments show that ensemble methods can substantially boost model performance.\",\n",
    "    \"We analyze the scalability of various machine learning algorithms when applied to large datasets.\",\n",
    "    \"Our findings suggest that hyperparameter tuning is crucial for achieving optimal results in machine learning applications.\",\n",
    "    \"This research highlights the importance of feature engineering in the context of predictive modeling.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65c0645-7ff6-483d-aa8e-88205c049e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# All inputs must have the same length\n",
    "# Ensure all inputs have the same length by adding a dummy token at the end\n",
    "# This process of adding dummy tokens is called padding.\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1027505-5c95-4fae-bdc3-c90b22726d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[ 1212,  3348, 10969,   257,   649,  2446,   329, 10068,   262,  2854,\n",
       "            286,  4572,  4673,  4981,   416,  1262,  1366, 16339, 14374,  7605,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 1135, 18077,   257,  5337,  3164,   284,  3288,  3303,  7587,   326,\n",
       "          17124,  1095,   262,  1176,   286,  6121,   364,   290,  3241, 11701,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[  818,   428,  2050,    11,   356,  9161,   262,  2928,   286,  2769,\n",
       "           4673, 16113,   319,   262,  9922,   286,  2939,  9465,  8861,    13,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 5122,  2267, 15687,   262, 13530,   286,  4351,  4673,   287, 27496,\n",
       "            262,  9889,   286, 17019,  7686,    13, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 1212,   670, 25409,   262,   779,   286, 37414,  4673,   329, 45780,\n",
       "           2551,    12,  8601,  7767,   287,  3716, 12493,    13, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 1135, 10400,   257,  9355,   329,   555, 16668, 16149,  4673,   326,\n",
       "           5566, 12850,   262,   761,   329, 15494,  1366,    13, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[  464,  2482,   286,   674, 10256,   905,   326, 34549,  5050,   460,\n",
       "          13788,  5750,  2746,  2854,    13, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 1135, 16602,   262, 16578,  1799,   286,  2972,  4572,  4673, 16113,\n",
       "            618,  5625,   284,  1588, 40522,    13, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 5122,  6373,  1950,   326,  8718, 17143,  2357, 24549,   318,  8780,\n",
       "            329, 16937, 16586,  2482,   287,  4572,  4673,  5479,    13, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 1212,  2267, 11330,   262,  6817,   286,  3895,  8705,   287,   262,\n",
       "           4732,   286, 33344, 21128,    13, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the data\n",
    "Tokenized_data=[tokenizer.encode_plus(\n",
    "    sentence,\n",
    "    add_special_tokens=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    max_length=50) for sentence in data]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b727f007-06f3-43b7-94d1-db021b9763c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[ 1212,  3348, 10969,   257,   649,  2446,   329, 10068,   262,  2854,\n",
       "            286,  4572,  4673,  4981,   416,  1262,  1366, 16339, 14374,  7605,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])},\n",
       " {'input_ids': tensor([[ 1135, 18077,   257,  5337,  3164,   284,  3288,  3303,  7587,   326,\n",
       "          17124,  1095,   262,  1176,   286,  6121,   364,   290,  3241, 11701,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]])}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenized_data[:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7642ff59-ff41-4c3f-8f5c-180c2e502b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the input IDs and the attention masks\n",
    "inputs_ids = [item['input_ids'].squeeze() for item in Tokenized_data]\n",
    "attention_masks = [item['attention_mask'].squeeze() for item in Tokenized_data]\n",
    "attention_masks[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d706a631-3a26-405c-9d0a-67352da2b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the input ids and attention masks to  tensors\n",
    "# This step is necessary for processing the  tuned model\n",
    "\n",
    "inputs_ids = torch.stack(inputs_ids)\n",
    "attention_masks = torch.stack(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2affb15d-ed87-4b2c-a715-6a8a7b8f856a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1212,  3348, 10969,   257,   649,  2446,   329, 10068,   262,  2854,\n",
       "           286,  4572,  4673,  4981,   416,  1262,  1366, 16339, 14374,  7605,\n",
       "            13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 1135, 18077,   257,  5337,  3164,   284,  3288,  3303,  7587,   326,\n",
       "         17124,  1095,   262,  1176,   286,  6121,   364,   290,  3241, 11701,\n",
       "            13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [  818,   428,  2050,    11,   356,  9161,   262,  2928,   286,  2769,\n",
       "          4673, 16113,   319,   262,  9922,   286,  2939,  9465,  8861,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 5122,  2267, 15687,   262, 13530,   286,  4351,  4673,   287, 27496,\n",
       "           262,  9889,   286, 17019,  7686,    13, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 1212,   670, 25409,   262,   779,   286, 37414,  4673,   329, 45780,\n",
       "          2551,    12,  8601,  7767,   287,  3716, 12493,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 1135, 10400,   257,  9355,   329,   555, 16668, 16149,  4673,   326,\n",
       "          5566, 12850,   262,   761,   329, 15494,  1366,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [  464,  2482,   286,   674, 10256,   905,   326, 34549,  5050,   460,\n",
       "         13788,  5750,  2746,  2854,    13, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 1135, 16602,   262, 16578,  1799,   286,  2972,  4572,  4673, 16113,\n",
       "           618,  5625,   284,  1588, 40522,    13, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 5122,  6373,  1950,   326,  8718, 17143,  2357, 24549,   318,  8780,\n",
       "           329, 16937, 16586,  2482,   287,  4572,  4673,  5479,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [ 1212,  2267, 11330,   262,  6817,   286,  3895,  8705,   287,   262,\n",
       "          4732,   286, 33344, 21128,    13, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e8b22c2-25eb-4320-b21a-1aca9cf8b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding all input sequences to ensure they have the same length\n",
    "padded_input_ids = pad_sequence(\n",
    "    inputs_ids,\n",
    "    batch_first = True,\n",
    "    padding_value = tokenizer.eos_token_id) # Use the tokenizer's end-of-sequence token ID as the padding value\n",
    "\n",
    "# Padding all attention masks to ensure they have the same length\n",
    "padded_attention_masks = pad_sequence(\n",
    "    attention_masks,\n",
    "    batch_first = True,\n",
    "    padding_value = 0) # Use 0 as the padding value for attention masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04ba78-5b1a-4288-a647-7067c64d39c6",
   "metadata": {},
   "source": [
    "Create the dataset include datalabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d148fd-9857-4484-bff0-6e86570785f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self,input_ids,attention_masks):\n",
    "        self.input_ids=input_ids\n",
    "        self.attention_masks=attention_masks\n",
    "        self.labels=input_ids.clone()\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return{\n",
    "            'input_ids':self.input_ids[idx],\n",
    "            'attention_masks':self.attention_masks[idx],\n",
    "            'labels':self.labels[idx]\n",
    "        }\n",
    "dataset=TextDataset(padded_input_ids,padded_attention_masks)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384d48ec-8baa-4b60-b8fd-81d2ea209ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1212,  3348, 10969,   257,   649,  2446,   329, 10068,   262,  2854,\n",
       "            286,  4572,  4673,  4981,   416,  1262,  1366, 16339, 14374,  7605,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "         [ 1135, 18077,   257,  5337,  3164,   284,  3288,  3303,  7587,   326,\n",
       "          17124,  1095,   262,  1176,   286,  6121,   364,   290,  3241, 11701,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]),\n",
       " 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]]),\n",
       " 'labels': tensor([[ 1212,  3348, 10969,   257,   649,  2446,   329, 10068,   262,  2854,\n",
       "            286,  4572,  4673,  4981,   416,  1262,  1366, 16339, 14374,  7605,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "         [ 1135, 18077,   257,  5337,  3164,   284,  3288,  3303,  7587,   326,\n",
       "          17124,  1095,   262,  1176,   286,  6121,   364,   290,  3241, 11701,\n",
       "             13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c41089-a425-4a62-b674-472bf3ae0e80",
   "metadata": {},
   "source": [
    "## Fine Tuning the gpt -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3107c980-59d7-4e86-9bb2-1418c0a79abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=DataLoader(dataset,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5018a15-acd1-4c67-bf32-90f7dffce812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x256841ff290>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8b74e95-9475-4610-8f7f-907f042e808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 1.3565013408660889\n",
      "Epoch 2 - Loss: 1.15887451171875\n",
      "Epoch 3 - Loss: 0.8793573379516602\n",
      "Epoch 4 - Loss: 0.8603087663650513\n",
      "Epoch 5 - Loss: 0.6487030982971191\n",
      "Epoch 6 - Loss: 0.5872219204902649\n",
      "Epoch 7 - Loss: 0.5017762780189514\n",
      "Epoch 8 - Loss: 0.33895784616470337\n",
      "Epoch 9 - Loss: 0.3879915475845337\n",
      "Epoch 10 - Loss: 0.16615575551986694\n"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.AdamW(model.parameters(),lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "\n",
    "#Training loop\n",
    "for epoch in range(10):\n",
    "    for batch in dataloader:\n",
    "        #unpacking the inputs and attention mask ids\n",
    "        input_ids=batch['input_ids']\n",
    "        attention_mask=batch['attention_masks']\n",
    "\n",
    "        #reset the gradient to zero [Every time we iterate it set optimization to zero]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward pass\n",
    "        #Processing the inputs and attention masks\n",
    "        outputs=model(input_ids=input_ids,attention_mask=attention_mask,\n",
    "                     labels=input_ids)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass: compute the gradients of the loss\n",
    "        loss.backward()\n",
    "    \n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        #print the loss of current epoch\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {loss.item()}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57d5c736-d451-42b8-ad5e-93a800915e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to generate text\n",
    "def generate_text(prompt,model,tokenizer,max_length=100):\n",
    "    # Encode the prompt to obtain input IDs and attention mask\n",
    "    inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Extract input ids and attention mask\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    outputs=model.generate(input_ids,attention_mask=attention_mask,\n",
    "                            max_length=max_length)\n",
    "    return tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1eea8da-af1a-4988-8b5f-c4bdae877dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this research ,we ert the use of machine learning algorithms for image recognition tasks.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"In this research ,we \"\n",
    "text_generated = generate_text(prompt, model, tokenizer, max_length = 500)\n",
    "print(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34df9d-5cf5-4dc2-8cd3-7e0b69b9aa8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
