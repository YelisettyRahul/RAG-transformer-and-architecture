# RAG-transformer-and-architecture
Fine tuning of Gpt-2 using attention masking
